{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717f602d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# notebooks/01_Exploratory_Leadership_Analysis.ipynb\n",
    "\n",
    "# --- Configuração Inicial do Ambiente (Necessário para imports de src) ---\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Adiciona o diretório raiz do projeto ao sys.path\n",
    "# Para notebooks, __file__ não é definido, então usamos um método alternativo\n",
    "# para encontrar o diretório do notebook e, a partir dele, a raiz do projeto.\n",
    "current_notebook_dir = os.getcwd() # Obtém o diretório de trabalho atual (deve ser 'notebooks/')\n",
    "# Sobe um nível de 'notebooks/' para 'transdevs_techexperience/'\n",
    "project_root = os.path.abspath(os.path.join(current_notebook_dir, '..'))\n",
    "\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "# --- Importações Necessárias ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import pickle # Para carregar modelos salvos\n",
    "import logging\n",
    "\n",
    "# Configurar o logging para exibir no notebook, se desejar (opcional, notebooks já printam)\n",
    "# logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Importa as configurações e funções do nosso projeto\n",
    "from src.config import (\n",
    "    EDA_FINAL_PATH, ANONYMIZED_PII_PATH, LEADERSHIP_TYPES, GROUP_NAMES,\n",
    "    TEXT_COLUMNS_FOR_NLP, TOPIC_MODEL_PATH, TFIDF_VECTORIZER_PATH,\n",
    "    TOPIC_TO_GROUP_APTITUDE_MAP, POSITIVE_WORDS, NEGATIVE_WORDS\n",
    ")\n",
    "from src.analysis.nlp_processing import (\n",
    "    tokenize_and_lemmatize, clean_text, correct_typos_and_standardize,\n",
    "    extract_ngrams, vectorize_text_tfidf, apply_topic_modeling_lda, analyze_sentiment\n",
    ")\n",
    "from src.analysis.leadership_analysis import (\n",
    "    load_eda_data, load_pii_mapping # Vamos redefinir a lógica mais avançada aqui no notebook para teste\n",
    ")\n",
    "\n",
    "# --- Carregar Dados ---\n",
    "print(\"Carregando dados para análise no notebook...\")\n",
    "df_eda = load_eda_data()\n",
    "df_pii = load_pii_mapping()\n",
    "\n",
    "if df_eda.empty:\n",
    "    print(\"Erro: DataFrame da EDA está vazio. Certifique-se de ter executado 'run_eda.py'.\")\n",
    "    sys.exit() # Sai do notebook se não houver dados\n",
    "\n",
    "print(f\"DataFrame EDA carregado com {len(df_eda)} registros.\")\n",
    "print(f\"DataFrame PII carregado com {len(df_pii)} registros (para referência segura).\")\n",
    "\n",
    "# Juntar os nomes para facilitar a visualização no notebook (com segurança, pois é ambiente local)\n",
    "if not df_pii.empty:\n",
    "    df_eda_with_names = df_eda.merge(df_pii[['participant_id', 'nome_completo']], on='participant_id', how='left')\n",
    "else:\n",
    "    df_eda_with_names = df_eda.copy()\n",
    "    df_eda_with_names['nome_completo'] = df_eda_with_names['participant_id'].apply(lambda x: f\"Participante_{x}\")\n",
    "\n",
    "# --- Análise do Gap de Preferências de Liderança ---\n",
    "\n",
    "print(\"\\n--- Análise do Gap de Preferências de Liderança ---\")\n",
    "\n",
    "# Identificar os grupos que ainda precisam de líderes diretos (baseado na run_eda.py anterior)\n",
    "# Aqui, vamos simular a lógica da run_eda.py para saber quais grupos ficaram sem líder direto\n",
    "direct_leaders_df = df_eda[df_eda['interesse_lideranca'] == LEADERSHIP_TYPES['DIRETA']].copy()\n",
    "group_leadership_status = {group: {'leader_id': None, 'leader_name': None, 'type': None, 'preferred_by_direct': []} for group in GROUP_NAMES}\n",
    "\n",
    "for idx, row in direct_leaders_df.iterrows():\n",
    "    participant_id = row['participant_id']\n",
    "    pref_group = row['grupo_principal']\n",
    "    alt_group = row['grupo_alternativo']\n",
    "\n",
    "    if group_leadership_status[pref_group]['leader_id'] is None:\n",
    "        group_leadership_status[pref_group]['leader_id'] = participant_id\n",
    "    elif alt_group != 'Não tenho interesse por nenhuma outra opção' and group_leadership_status[alt_group]['leader_id'] is None:\n",
    "        group_leadership_status[alt_group]['leader_id'] = participant_id\n",
    "\n",
    "groups_needing_leaders = [group for group, status in group_leadership_status.items() if status['leader_id'] is None]\n",
    "\n",
    "print(f\"Grupos que ainda precisam de liderança direta: {groups_needing_leaders}\")\n",
    "\n",
    "# Pessoas que querem \"ajudar na liderança\"\n",
    "support_leaders_candidates = df_eda_with_names[df_eda_with_names['interesse_lideranca'] == LEADERSHIP_TYPES['SUPORTE']].copy()\n",
    "\n",
    "print(f\"\\nTotal de candidatos a líder de suporte: {len(support_leaders_candidates)}\")\n",
    "print(\"Preferências de grupo dos candidatos a líder de suporte:\")\n",
    "print(support_leaders_candidates[['nome_completo', 'grupo_principal', 'grupo_alternativo']])\n",
    "\n",
    "# Verificar o alinhamento das preferências dos candidatos de suporte com os grupos carentes\n",
    "alignment_data = []\n",
    "for idx, row in support_leaders_candidates.iterrows():\n",
    "    name = row['nome_completo']\n",
    "    main_pref = row['grupo_principal']\n",
    "    alt_pref = row['grupo_alternativo']\n",
    "    \n",
    "    main_match = main_pref in groups_needing_leaders\n",
    "    alt_match = alt_pref in groups_needing_leaders if alt_pref != 'Não tenho interesse por nenhuma outra opção' else False\n",
    "    \n",
    "    alignment_data.append({\n",
    "        'nome_completo': name,\n",
    "        'grupo_principal_pref': main_pref,\n",
    "        'grupo_alternativo_pref': alt_pref,\n",
    "        'main_pref_needs_leader': main_match,\n",
    "        'alt_pref_needs_leader': alt_match,\n",
    "        'aligned_to_needing_group': main_match or alt_match\n",
    "    })\n",
    "\n",
    "df_alignment = pd.DataFrame(alignment_data)\n",
    "\n",
    "print(\"\\nAlinhamento dos candidatos a líder de suporte com os grupos que precisam de líderes:\")\n",
    "print(df_alignment)\n",
    "\n",
    "if not df_alignment['aligned_to_needing_group'].any():\n",
    "    print(\"\\nCONFIRMADO: Nenhum candidato a líder de suporte tem como preferência direta (principal ou alternativa) os grupos que ainda precisam de líderes.\")\n",
    "    print(\"Isso explica a mensagem anterior. Precisamos de uma lógica mais avançada para sugerir.\")\n",
    "else:\n",
    "    print(\"\\nAlguns candidatos a líder de suporte se alinham com os grupos que precisam de líderes. Vamos usar a lógica avançada para sugerir.\")\n",
    "\n",
    "\n",
    "# --- Exploração Detalhada dos Tópicos LDA para Mapeamento ---\n",
    "\n",
    "print(\"\\n--- Exploração Detalhada dos Tópicos LDA para Mapeamento ---\")\n",
    "\n",
    "# Carregar o vetorizador TF-IDF e o modelo LDA salvos\n",
    "try:\n",
    "    with open(TFIDF_VECTORIZER_PATH, 'rb') as f:\n",
    "        tfidf_vectorizer = pickle.load(f)\n",
    "    with open(TOPIC_MODEL_PATH, 'rb') as f:\n",
    "        lda_model = pickle.load(f)\n",
    "    print(\"Modelos TF-IDF e LDA carregados com sucesso.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Erro: Modelos TF-IDF ou LDA não encontrados. Certifique-se de ter executado 'run_eda.py'.\")\n",
    "    sys.exit()\n",
    "\n",
    "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "\n",
    "def display_topics(model, feature_names, no_top_words):\n",
    "    \"\"\"Exibe as top palavras para cada tópico.\"\"\"\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(f\"Tópico {topic_idx+1}:\")\n",
    "        print(\" \".join([f\"{feature_names[i]} ({topic[i]:.2f})\"\n",
    "                        for i in topic.argsort()[:-no_top_words - 1:-1]]))\n",
    "    print(\"\\n\")\n",
    "\n",
    "print(f\"\\nPalavras-chave dos Tópicos (Top 10 com pesos):\")\n",
    "display_topics(lda_model, feature_names, 10)\n",
    "\n",
    "\n",
    "# Recalcular a distribuição de tópicos por participante (se não estiver em df_eda)\n",
    "if 'main_topic' not in df_eda.columns:\n",
    "    # Gerar textos limpos para vetorização (como no run_eda.py)\n",
    "    text_for_topic_modeling = df_eda[TEXT_COLUMNS_FOR_NLP].fillna('').agg(' '.join, axis=1).apply(correct_typos_and_standardize).apply(clean_text)\n",
    "    \n",
    "    # Vetorizar os textos\n",
    "    tfidf_matrix = tfidf_vectorizer.transform(text_for_topic_modeling)\n",
    "    \n",
    "    # Obter as distribuições de tópico\n",
    "    topic_distribution = lda_model.transform(tfidf_matrix)\n",
    "    \n",
    "    df_eda['main_topic'] = np.argmax(topic_distribution, axis=1) + 1\n",
    "    for i in range(lda_model.n_components):\n",
    "        df_eda[f'topic_{i+1}_score'] = topic_distribution[:, i]\n",
    "    print(\"Colunas de tópicos adicionadas ao df_eda.\")\n",
    "\n",
    "print(\"\\nDistribuição de Grupos Principais por Tópico Principal (Top 3 por Tópico):\")\n",
    "for topic_id in sorted(df_eda['main_topic'].unique()):\n",
    "    topic_group_prefs = df_eda[df_eda['main_topic'] == topic_id]['grupo_principal'].value_counts(normalize=True).head(3) * 100\n",
    "    if not topic_group_prefs.empty:\n",
    "        print(f\"--- Tópico {topic_id} ---\")\n",
    "        print(topic_group_prefs.apply(lambda x: f\"{x:.2f}%\"))\n",
    "        print(\"-\" * 20)\n",
    "\n",
    "print(\"\\nDistribuição de Grupos Alternativos por Tópico Principal (Top 3 por Tópico):\")\n",
    "for topic_id in sorted(df_eda['main_topic'].unique()):\n",
    "    topic_group_alt_prefs = df_eda[df_eda['main_topic'] == topic_id]['grupo_alternativo'].value_counts(normalize=True).head(3) * 100\n",
    "    if not topic_group_alt_prefs.empty:\n",
    "        print(f\"--- Tópico {topic_id} ---\")\n",
    "        print(topic_group_alt_prefs.apply(lambda x: f\"{x:.2f}%\"))\n",
    "        print(\"-\" * 20)\n",
    "\n",
    "\n",
    "# --- EXERCÍCIO INTERATIVO: Refinar o Mapeamento Tópico-Grupo ---\n",
    "print(\"\\n--- EXERCÍCIO: Refine o Mapeamento Tópico-Grupo ---\")\n",
    "print(\"Ajuste os pesos (0.0 a 1.0) para cada grupo em cada tópico com base nas palavras-chave e nas distribuições acima.\")\n",
    "print(\"Um peso maior indica maior aptidão do tópico para aquele grupo. Salvaremos este mapa no config.py.\")\n",
    "\n",
    "# Esta é a versão do config.py. Copie para cá e ajuste.\n",
    "TOPIC_TO_GROUP_APTITUDE_MAP_NOTEBOOK = {\n",
    "    1: {'G1 - Automações Wix': 0.4, 'G2 - API de Orquestração': 0.4, 'G3 - Integração WhatsApp': 0.4, 'G4 - SUPABASE (Banco de Dados)': 0.4}, # Tópico 1 (Busca Conhecimento) - Aptidão geral\n",
    "    2: {'G1 - Automações Wix': 0.6, 'G2 - API de Orquestração': 0.6, 'G3 - Integração WhatsApp': 0.6, 'G4 - SUPABASE (Banco de Dados)': 0.6}, # Tópico 2 (Desenvolvimento/Recursos) - Aptidão para organização e processos\n",
    "    3: {'G1 - Automações Wix': 0.7, 'G2 - API de Orquestração': 0.7, 'G3 - Integração WhatsApp': 0.7, 'G4 - SUPABASE (Banco de Dados)': 0.7}, # Tópico 3 (Comunidade/Inclusão) - Aptidão para foco em pessoas\n",
    "    4: {'G1 - Automações Wix': 0.3, 'G2 - API de Orquestração': 0.8, 'G3 - Integração WhatsApp': 0.3, 'G4 - SUPABASE (Banco de Dados)': 0.9}, # Tópico 4 (Análise/Gestão/Network) - Forte para G2 (API), G4 (Dados)\n",
    "    5: {'G1 - Automações Wix': 0.9, 'G2 - API de Orquestração': 0.4, 'G3 - Integração WhatsApp': 0.9, 'G4 - SUPABASE (Banco de Dados)': 0.4}, # Tópico 5 (Projetos/Criação/Colaboração) - Forte para G1 (Wix) e G3 (WhatsApp)\n",
    "}\n",
    "\n",
    "print(\"\\n--- Mapeamento Tópico-Grupo Atualizado (Ajuste os pesos no código acima) ---\")\n",
    "for topic_id, group_scores in TOPIC_TO_GROUP_APTITUDE_MAP_NOTEBOOK.items():\n",
    "    print(f\"Tópico {topic_id}: {group_scores}\")\n",
    "\n",
    "\n",
    "# --- Nova Lógica de Potencial de Liderança (para simular e testar aqui) ---\n",
    "print(\"\\n--- Teste da Nova Lógica de Potencial de Liderança ---\")\n",
    "\n",
    "def calculate_aptitude_score(row, group_needed, topic_to_group_map, sentiment_cols, lda_model_components):\n",
    "    \"\"\"Calcula o score de aptidão de um participante para um grupo específico.\"\"\"\n",
    "    score = 0.0\n",
    "\n",
    "    # 1. Alinhamento de Preferência Direta\n",
    "    if row['grupo_principal'] == group_needed:\n",
    "        score += 0.5\n",
    "    elif row['grupo_alternativo'] == group_needed:\n",
    "        score += 0.3\n",
    "\n",
    "    # 2. Alinhamento de Tópicos (usando o mapa refinado do notebook)\n",
    "    main_topic_id = row['main_topic'] if not pd.isna(row['main_topic']) else None\n",
    "    if main_topic_id is not None and main_topic_id in topic_to_group_map:\n",
    "        topic_aptitude = topic_to_group_map[main_topic_id].get(group_needed, 0)\n",
    "        score += topic_aptitude * 0.7 # Peso do alinhamento do tópico\n",
    "\n",
    "    # 3. Score de Sentimento Ponderado (Proatividade, Engajamento)\n",
    "    sentiment_score = sum(1 for col in sentiment_cols if col in row and row[col] == 'Positivo') - \\\n",
    "                      sum(1 for col in sentiment_cols if col in row and row[col] == 'Negativo')\n",
    "    score += sentiment_score * 0.1\n",
    "\n",
    "    return score\n",
    "\n",
    "# Simular a atribuição para líderes diretos e identificar grupos carentes\n",
    "temp_group_leadership_status = {group: {'leader_id': None, 'type': None} for group in GROUP_NAMES}\n",
    "for idx, row in df_eda.iterrows():\n",
    "    if row['interesse_lideranca'] == LEADERSHIP_TYPES['DIRETA']:\n",
    "        participant_id = row['participant_id']\n",
    "        pref_group = row['grupo_principal']\n",
    "        alt_group = row['grupo_alternativo']\n",
    "        \n",
    "        assigned = False\n",
    "        if temp_group_leadership_status[pref_group]['leader_id'] is None:\n",
    "            temp_group_leadership_status[pref_group]['leader_id'] = participant_id\n",
    "            temp_group_leadership_status[pref_group]['type'] = 'Direta (Principal)'\n",
    "            assigned = True\n",
    "        elif alt_group != 'Não tenho interesse por nenhuma outra opção' and temp_group_leadership_status[alt_group]['leader_id'] is None:\n",
    "            temp_group_leadership_status[alt_group]['leader_id'] = participant_id\n",
    "            temp_group_leadership_status[alt_group]['type'] = 'Direta (Alternativa)'\n",
    "            assigned = True\n",
    "        \n",
    "        if assigned:\n",
    "            df_eda.loc[df_eda['participant_id'] == participant_id, 'sim_status_lideranca_final'] = f\"Líder Direto Atribuído ({temp_group_leadership_status[pref_group]['type']})\"\n",
    "            df_eda.loc[df_eda['participant_id'] == participant_id, 'sim_sugestao_lideranca_grupo'] = pref_group # Ou alt_group, dependendo\n",
    "        else:\n",
    "             df_eda.loc[df_eda['participant_id'] == participant_id, 'sim_status_lideranca_final'] = \"Líder Direto (sem atribuição por conflito)\"\n",
    "             df_eda.loc[df_eda['participant_id'] == participant_id, 'sim_sugestao_lideranca_grupo'] = 'N/A'\n",
    "\n",
    "\n",
    "groups_needing_leaders_sim = [group for group, status in temp_group_leadership_status.items() if status['leader_id'] is None]\n",
    "print(f\"\\nGrupos simulados ainda sem liderança direta: {groups_needing_leaders_sim}\")\n",
    "\n",
    "# Filtrar e calcular scores para potenciais líderes de suporte\n",
    "potential_support_sim_insights = []\n",
    "for idx, row in df_eda.iterrows():\n",
    "    if row['interesse_lideranca'] == LEADERSHIP_TYPES['SUPORTE']:\n",
    "        participant_id = row['participant_id']\n",
    "        best_aptitude_score = -1\n",
    "        best_suggested_group = 'N/A'\n",
    "\n",
    "        for group_needed in groups_needing_leaders_sim:\n",
    "            score = calculate_aptitude_score(row, group_needed, TOPIC_TO_GROUP_APTITUDE_MAP_NOTEBOOK, ['objetivo_proposito_sentiment', 'bagagem_contribuicao_sentiment', 'compromisso_pessoal_sentiment'], lda_model.components_)\n",
    "            if score > best_aptitude_score:\n",
    "                best_aptitude_score = score\n",
    "                best_suggested_group = group_needed\n",
    "        \n",
    "        if best_aptitude_score > 0:\n",
    "            potential_support_sim_insights.append({\n",
    "                'participant_id': participant_id,\n",
    "                'nome_completo': df_eda_with_names.loc[df_eda_with_names['participant_id'] == participant_id, 'nome_completo'].iloc[0],\n",
    "                'sugestao_lideranca_grupo': best_suggested_group,\n",
    "                'aptidao_score_geral': round(best_aptitude_score, 2),\n",
    "                'justificativa_bagagem': row['bagagem_contribuicao_cleaned'],\n",
    "                'justificativa_topico_lda': f\"Tópico {int(row['main_topic'])}\" if not pd.isna(row['main_topic']) else \"N/A\",\n",
    "                'justificativa_sentimento': row['objetivo_proposito_sentiment'] + \"/\" + row['bagagem_contribuicao_sentiment'],\n",
    "            })\n",
    "\n",
    "df_potential_leaders_sim = pd.DataFrame(potential_support_sim_insights)\n",
    "\n",
    "print(\"\\n--- Sugestões de Potenciais Líderes de Suporte (SIMULADO NO NOTEBOOK) ---\")\n",
    "if not df_potential_leaders_sim.empty:\n",
    "    print(df_potential_leaders_sim.sort_values(by='aptidao_score_geral', ascending=False).head())\n",
    "else:\n",
    "    print(\"Nenhum potencial líder de suporte identificado com a lógica atual para os grupos carentes.\")\n",
    "\n",
    "print(\"\\n--- FIM DA ANÁLISE INTERATIVA ---\")\n",
    "print(\"Após refinar o TOPIC_TO_GROUP_APTITUDE_MAP_NOTEBOOK, atualize o dicionário TOPIC_TO_GROUP_APTITUDE_MAP em src/config.py.\")\n",
    "print(\"Em seguida, execute 'python run_eda.py' e depois 'streamlit run src/app/main.py' para ver as mudanças no dashboard.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
