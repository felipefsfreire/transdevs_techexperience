# Projeto TransDevs TechExperience: Conectando InovaÃ§Ã£o e InclusÃ£o

## VisÃ£o Geral

Este projeto Ã© uma iniciativa do TransDevs TechExperience, focado em utilizar Data Analytics e Machine Learning para aprimorar a experiÃªncia de suas pessoas participantes. Nosso objetivo Ã© transformar dados de check-in em *insights* acionÃ¡veis, promovendo a inclusÃ£o e o desenvolvimento na comunidade tech. O dashboard interativo, construÃ­do com Streamlit, captura o lado humano e o "feeling" das pessoas inscritas, auxiliando na construÃ§Ã£o de perfis e no match para futuras conexÃµes e oportunidades.

Trabalhamos com foco em soluÃ§Ãµes reprodutÃ­veis, explicÃ¡veis e alinhadas aos princÃ­pios de Diversidade, Equidade e InclusÃ£o (DE&I).

## Objetivos do Dashboard

O dashboard visa responder a perguntas estratÃ©gicas e fornecer uma compreensÃ£o aprofundada da comunidade:

*   **Perfil de Interesse:** Quais sÃ£o os interesses predominantes (grupos de trabalho, aspiraÃ§Ãµes profissionais) das pessoas inscritas?
*   **Engajamento e LideranÃ§a:** Qual o nÃ­vel de interesse em papÃ©is de lideranÃ§a ou suporte, e como podemos identificar e alocar esses talentos nos grupos?
*   **TÃ³picos e Temas:** Quais sÃ£o os principais tÃ³picos e temas de interesse da comunidade (habilidades, objetivos, expectativas de projeto), extraÃ­dos de campos de texto livre?
*   **Sentimento da Comunidade:** Como o sentimento geral e especÃ­fico (por tema) da comunidade se manifesta em relaÃ§Ã£o ao projeto, seus objetivos e desafios, incluindo a percepÃ§Ã£o de desafios e otimismo?
*   **Barreiras e Oportunidades:** Identificar as principais expectativas e possÃ­veis desafios enfrentados pelas pessoas em suas jornadas e como o projeto pode contribuir.

## ğŸ“ Estrutura do Projeto

A aplicaÃ§Ã£o segue uma arquitetura modular para facilitar a manutenÃ§Ã£o e escalabilidade:

```text
transdevs_techexperience/
â”œâ”€â”€ .streamlit/                # ConfiguraÃ§Ãµes do Streamlit (inclui secrets.toml)
â”‚   â””â”€â”€ secrets.toml           # **SENHAS E CHAVES SECRETAS (NÃƒO VAI PARA GIT!)**
â”œâ”€â”€ assets/                    # Ativos estÃ¡ticos como imagens e Ã­cones
â”‚   â””â”€â”€ images/                # Imagens do projeto (ex: logo da DiversificaDev)
â”‚       â””â”€â”€ diversificadev_logo.png
â”œâ”€â”€ data/                      # Armazena os dados
â”‚   â”œâ”€â”€ raw/                   # Dados brutos originais (CSV do formulÃ¡rio)
â”‚   â”‚   â””â”€â”€ Checkin TransDevs TechExperience (respostas) - Respostas ao formulÃ¡rio 1.csv
â”‚   â””â”€â”€ processed/             # Dados limpos, transformados e insights gerados (CSVs processados)
â”œâ”€â”€ models/                    # Modelos de Machine Learning treinados (LDA, TF-IDF Vectorizer)
â”œâ”€â”€ notebooks/                 # Jupyter Notebooks para exploraÃ§Ã£o e prototipagem
â”‚   â””â”€â”€ 01_Exploratory_Leadership_Analysis.ipynb
â”œâ”€â”€ src/                       # CÃ³digo fonte da aplicaÃ§Ã£o
â”‚   â”œâ”€â”€ analysis/              # MÃ³dulos para EDA, NLP e anÃ¡lises especÃ­ficas
â”‚   â”‚   â”œâ”€â”€ __init__.py        # Indica que 'analysis' Ã© um pacote Python
â”‚   â”‚   â”œâ”€â”€ eda.py             # FunÃ§Ãµes de AnÃ¡lise ExploratÃ³ria de Dados
â”‚   â”‚   â”œâ”€â”€ leadership_analysis.py # LÃ³gica de identificaÃ§Ã£o de lÃ­deres
â”‚   â”‚   â””â”€â”€ nlp_processing.py  # FunÃ§Ãµes de Processamento de Linguagem Natural
â”‚   â”œâ”€â”€ app/                   # MÃ³dulos da aplicaÃ§Ã£o Streamlit
â”‚   â”‚   â”œâ”€â”€ __init__.py        # Indica que 'app' Ã© um pacote Python
â”‚   â”‚   â”œâ”€â”€ main.py            # Script principal do Dashboard Streamlit
â”‚   â”‚   â””â”€â”€ utils.py           # FunÃ§Ãµes utilitÃ¡rias e estilos do Dashboard
â”‚   â”œâ”€â”€ config.py              # VariÃ¡veis de configuraÃ§Ã£o, caminhos, constantes, lÃ©xicos
â”‚   â”œâ”€â”€ data_ingestion.py      # LÃ³gica de carregamento de dados brutos
â”‚   â””â”€â”€ data_processing.py     # LÃ³gica de limpeza e padronizaÃ§Ã£o de dados
â”œâ”€â”€ .env                       # VariÃ¡veis de ambiente (opcional, mas boa prÃ¡tica)
â”œâ”€â”€ .gitignore                 # Arquivos e pastas a serem ignorados pelo Git
â”œâ”€â”€ nltk_download_script.py    # Script para baixar recursos do NLTK e spaCy
â”œâ”€â”€ README.md                  # Este arquivo de documentaÃ§Ã£o
â”œâ”€â”€ requirements.txt           # Lista de dependÃªncias Python
â”œâ”€â”€ run_eda.py                 # Script para executar o pipeline de EDA e gerar insights
â””â”€â”€ run_pipeline.py            # Script para executar o pipeline ETL inicial
```

## Tecnologias Utilizadas

*   **Python:** Linguagem de programaÃ§Ã£o principal (versÃ£o 3.8+).
*   **Pandas:** Biblioteca para manipulaÃ§Ã£o e anÃ¡lise de dados tabulares.
*   **NLTK & spaCy:** Bibliotecas essenciais para Processamento de Linguagem Natural (NLP), incluindo tokenizaÃ§Ã£o, lematizaÃ§Ã£o e remoÃ§Ã£o de stopwords. O spaCy Ã© preferido para lematizaÃ§Ã£o em portuguÃªs devido Ã  sua precisÃ£o.
*   **Scikit-learn:** Biblioteca de Machine Learning utilizada para Modelagem de TÃ³picos (LDA) e VetorizaÃ§Ã£o de texto (TF-IDF).
*   **WordCloud:** Biblioteca para geraÃ§Ã£o de nuvens de palavras impactantes.
*   **Streamlit:** Framework de cÃ³digo aberto para criaÃ§Ã£o rÃ¡pida de dashboards e aplicaÃ§Ãµes web interativas em Python.
*   **Plotly Express:** Biblioteca para geraÃ§Ã£o de grÃ¡ficos interativos e esteticamente alinhados Ã  identidade visual.
*   **Google Sheets:** Atua como a fonte de dados primÃ¡ria do projeto (lido via arquivo CSV exportado).

## Como Configurar e Executar o Projeto

### PrÃ©-requisitos

*   Python 3.8+ instalado.
*   `pip` (gerenciador de pacotes Python).
*   `git` (para clonar o repositÃ³rio, se aplicÃ¡vel).

### 1. Clonar o RepositÃ³rio (se aplicÃ¡vel)

```bash
git clone <URL_DO_SEU_REPOSITORIO_GIT>
cd transdevs_techexperience
```

### 2. Criar e Ativar o Ambiente Virtual (macOS/Linux)

Ã‰ altamente recomendado usar um ambiente virtual para gerenciar as dependÃªncias do projeto, garantindo isolamento e reprodutibilidade.

```bash
python3 -m venv .venv
source ./.venv/bin/activate
```
*   ApÃ³s ativar, o prompt do seu terminal deve exibir `(.venv)` no inÃ­cio.

### 3. Instalar DependÃªncias Python

Com o ambiente virtual **ativado**, instale todas as bibliotecas listadas no `requirements.txt`:

```bash
pip install -r requirements.txt
```

### 4. Baixar Recursos de NLP (NLTK e spaCy)

O NLTK e o spaCy precisam de dados adicionais para funcionar corretamente, como dicionÃ¡rios de stopwords e modelos de linguagem.

```bash
# Para NLTK:
python nltk_download_script.py

# Para spaCy (CRÃTICO: Baixa o modelo de portuguÃªs):
python -m spacy download pt_core_news_sm
```

### 5. Configurar Dados e Ativos Visuais

*   **Arquivo de Dados Brutos:** Coloque o arquivo CSV de respostas do formulÃ¡rio (`Checkin TransDevs TechExperience (respostas) - Respostas ao formulÃ¡rio 1.csv`) na pasta `data/raw/`. Este arquivo **nÃ£o deve ser commitado no Git**.
*   **Logo da DiversificaDev:** Coloque o arquivo da logo (ex: `diversificadev_logo.png`) na pasta `assets/images/`.

### 6. Configurar Credenciais do Dashboard (SeguranÃ§a)

Para proteger o acesso ao seu dashboard Streamlit, utilize o arquivo `secrets.toml`:

*   Crie uma pasta `.streamlit/` na raiz do seu projeto, se ainda nÃ£o existir.
*   Crie (ou edite) o arquivo `secrets.toml` dentro de `.streamlit/`.

**ConteÃºdo de `transdevs_techexperience/.streamlit/secrets.toml`:**
```toml
# .streamlit/secrets.toml
# Este arquivo contÃ©m segredos e credenciais sensÃ­veis.
# DEVE ser adicionado ao .gitignore e NUNCA commitado em repositÃ³rios pÃºblicos!

[user_credentials]
username = "transdevs" # Seu nome de usuÃ¡rio para login no dashboard
password = "sua_senha_secreta" # **MUDE ESTA SENHA PARA ALGO SEGURO E ÃšNICO!**
```
**IMPORTANTE:** Certifique-se de que o arquivo `.gitignore` (descrito abaixo) inclui `/.streamlit/secrets.toml` para que suas credenciais nÃ£o sejam publicadas.

### 7. Executar os Pipelines de Processamento de Dados (ETL e EDA)

Estes scripts irÃ£o processar os dados brutos, realizar as anÃ¡lises de NLP e gerar todos os *insights* necessÃ¡rios em arquivos CSV na pasta `data/processed/`.

```bash
# 1. Executar o pipeline de ETL inicial (carregamento e tratamento de PII)
python run_pipeline.py

# 2. Executar o pipeline de AnÃ¡lise ExploratÃ³ria de Dados (NLP, TÃ³picos, Sentimento, LideranÃ§a)
# Este comando gerarÃ¡ os arquivos CSV finais na pasta 'data/processed/'
python run_eda.py
```
*   **Nota:** Se vocÃª alterar `src/config.py`, `src/analysis/nlp_processing.py`, `src/analysis/eda.py` ou `src/analysis/leadership_analysis.py`, vocÃª precisarÃ¡ re-executar `python run_eda.py` para gerar os arquivos `data/processed/` atualizados antes de ver as mudanÃ§as no dashboard.

### 8. Executar o Dashboard Streamlit

Com os dados processados, inicie a aplicaÃ§Ã£o Streamlit:

```bash
streamlit run src/app/main.py
```
O dashboard serÃ¡ aberto no seu navegador padrÃ£o (geralmente `http://localhost:8501`). Uma tela de login solicitarÃ¡ o `username` e `password` configurados no seu `secrets.toml`.

## Privacidade e SeguranÃ§a de Dados

Aderimos aos princÃ­pios de privacidade e seguranÃ§a de dados, seguindo as melhores prÃ¡ticas (LGPD/GDPR):

*   **AnonimizaÃ§Ã£o/PseudonimizaÃ§Ã£o:** InformaÃ§Ãµes Pessoais IdentificÃ¡veis (PII) sensÃ­veis (como nome e telefone) sÃ£o imediatamente pseudonimizadas ou removidas no inÃ­cio do pipeline. O mapeamento (`anonymized_pii_mapping.csv`) Ã© para referÃªncia interna e **NUNCA deve ser exposto publicamente**.
*   **Controle de Acesso:** O dashboard Streamlit Ã© protegido por um sistema de login com credenciais armazenadas de forma segura via `secrets.toml` (localmente) ou `st.secrets` (no Streamlit Cloud).
*   **`.gitignore`:** Arquivos sensÃ­veis, dados processados e modelos treinados sÃ£o explicitamente ignorados pelo controle de versÃ£o para evitar exposiÃ§Ã£o acidental.

## `.gitignore`

O arquivo `.gitignore` garante que arquivos temporÃ¡rios, de ambiente e sensÃ­veis nÃ£o sejam incluÃ­dos no controle de versÃ£o.

```
# Python
__pycache__/
*.pyc
*.o
*.so
*.egg
*.egg-info/
.pytest_cache/
.tox/
.venv/
env/
venv/
pip-log.txt
pip-delete-this-directory.txt

# IDEs
.idea/
.vscode/

# Logs
*.log

# Dados gerados e processados (CRÃTICO)
data/processed/

# Dados brutos (CRÃTICO)
data/raw/Checkin TransDevs TechExperience (respostas) - Respostas ao formulÃ¡rio 1.csv

# Modelos de Machine Learning (CRÃTICO)
models/

# Streamlit secrets (CRÃTICO)
.streamlit/secrets.toml

# Notebook checkpoints
.ipynb_checkpoints/

# VariÃ¡veis de ambiente
.env
```

## Exportar Bibliotecas para `requirements.txt`

Sempre que novas bibliotecas forem instaladas com `pip install`, atualize o `requirements.txt` para manter a reprodutibilidade do ambiente:

```bash
pip freeze > requirements.txt
```
*   Execute este comando no terminal, com o ambiente virtual **ativado**, na raiz do projeto.

## PrÃ³ximos Passos e Melhorias Potenciais

*   **Refinamento ContÃ­nuo:** Ajuste dos lÃ©xicos de sentimento, `TYPO_CORRECTION_MAP` e `TOPIC_TO_GROUP_APTITUDE_MAP` com base em mais dados ou feedback.
*   **Matchmaking AvanÃ§ado:** Implementar funcionalidades para sugerir conexÃµes entre participantes ou oportunidades com base em perfis e lacunas.
*   **Feedback Loop:** Adicionar mecanismos para coletar feedback direto dos usuÃ¡rios do dashboard.
*   **Monitoramento de Vieses:** Integrar ferramentas de explicabilidade (XAI) para garantir que os modelos de ML sejam justos e transparentes.

## Colaboradores

*   **Desenvolvimento:** Felipe Freire
